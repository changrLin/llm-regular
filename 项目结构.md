# ğŸ“ é¡¹ç›®ç»“æ„ (Project Structure)

## å®Œæ•´ç›®å½•æ ‘

```
neurosymbolic-avo/
â”‚
â”œâ”€â”€ README.md                          # é¡¹ç›®æ¦‚è¿°ã€å®‰è£…æŒ‡å—ã€å¿«é€Ÿå¼€ï¿½ï¿½ï¿½
â”œâ”€â”€ LICENSE                            # å¼€æºåè®®ï¼ˆå¦‚MITï¼‰
â”œâ”€â”€ pyproject.toml                     # é¡¹ç›®é…ç½®ï¼ˆPEP 518æ ‡å‡†ï¼‰
â”œâ”€â”€ requirements.txt                   # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.py                           # å®‰è£…è„šæœ¬
â”œâ”€â”€ . gitignore                         # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ . env. example                       # ç¯å¢ƒå˜é‡æ¨¡æ¿ï¼ˆLLM API Keyç­‰ï¼‰
â”‚
â”œâ”€â”€ docs/                              # ğŸ“š æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ design/                        
â”‚   â”‚   â”œâ”€â”€ vibe_coding_v2.0.md       # Vibe Codingä¸»æ–‡æ¡£
â”‚   â”‚   â”œâ”€â”€ technical_supplement.md   # æŠ€æœ¯è¡¥å……æ–‡æ¡£
â”‚   â”‚   â””â”€â”€ engineering_details.md    # å·¥ç¨‹ç»†èŠ‚æ–‡æ¡£
â”‚   â”œâ”€â”€ api/                           # APIæ–‡æ¡£ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â””â”€â”€ tutorials/                     # æ•™ç¨‹
â”‚       â”œâ”€â”€ 01_quick_start.ipynb      # å¿«é€Ÿå¼€å§‹
â”‚       â”œâ”€â”€ 02_synthetic_data.ipynb   # åˆæˆæ•°æ®æµ‹è¯•
â”‚       â””â”€â”€ 03_real_data. ipynb        # çœŸå®æ•°æ®å¤„ç†
â”‚
â”œâ”€â”€ data/                              # ğŸ“Š æ•°æ®ç›®å½•ï¼ˆä¸æäº¤åˆ°gitï¼‰
â”‚   â”œâ”€â”€ raw/                           # åŸå§‹SEG-Yæ–‡ä»¶
â”‚   â”œâ”€â”€ synthetic/                     # åˆæˆæ•°æ®
â”‚   â””â”€â”€ results/                       # å¤„ç†ç»“æœ
â”‚       â”œâ”€â”€ velocity_spectra/          # é€Ÿåº¦è°±å›¾
â”‚       â””â”€â”€ logs/                      # å¤„ç†æ—¥å¿—
â”‚
â”œâ”€â”€ configs/                           # âš™ï¸ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ default.yaml                   # é»˜è®¤é…ç½®
â”‚   â”œâ”€â”€ agent_prompts.yaml             # Agentçš„Promptæ¨¡æ¿
â”‚   â””â”€â”€ physics_constraints.yaml       # ç‰©ç†å¸¸é‡å®šä¹‰
â”‚
â”œâ”€â”€ src/                               # ğŸ’» æºä»£ç ï¼ˆæ ¸å¿ƒæ¨¡å—ï¼‰
â”‚   â””â”€â”€ neurosymbolic_avo/
â”‚       â”œâ”€â”€ __init__.py                # åŒ…åˆå§‹åŒ–
â”‚       â”‚
â”‚       â”œâ”€â”€ core/                      # æ ¸å¿ƒç®—æ³•æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ data_structures.py     # CMPGather, SeismicFeaturesç­‰
â”‚       â”‚   â”œâ”€â”€ nmo. py                 # NMOæ ¡æ­£å®ç°
â”‚       â”‚   â”œâ”€â”€ features.py            # FeatureExtractorç±»
â”‚       â”‚   â”œâ”€â”€ avo_classification.py  # AVOåˆ†ç±»ç®—æ³•
â”‚       â”‚   â””â”€â”€ semblance.py           # ä¼ ç»ŸSemblanceè®¡ç®—
â”‚       â”‚
â”‚       â”œâ”€â”€ agent/                     # ğŸ§  Agentå†³ç­–æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ llm_agent.py           # SeismicAgentç±»
â”‚       â”‚   â”œâ”€â”€ prompts.py             # Promptæ¨¡æ¿å®šä¹‰
â”‚       â”‚   â”œâ”€â”€ blueprint.py           # KernelBlueprintæ•°æ®ç±»
â”‚       â”‚   â””â”€â”€ fallback. py            # è§„åˆ™å¼•æ“ï¼ˆLLMå¤±è´¥æ—¶ï¼‰
â”‚       â”‚
â”‚       â”œâ”€â”€ kernel/                    # ğŸ”§ æ ¸å‡½æ•°æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ factory.py             # KernelFactoryç±»
â”‚       â”‚   â”œâ”€â”€ registry.py            # æ ¸å‡½æ•°æ³¨å†Œè¡¨
â”‚       â”‚   â””â”€â”€ custom_kernels.py      # è‡ªå®šä¹‰æ ¸å‡½æ•°
â”‚       â”‚
â”‚       â”œâ”€â”€ solver/                    # ğŸ“ æ±‚è§£å™¨æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ map_solver.py          # MAPæ±‚è§£ï¼ˆCholeskyï¼‰
â”‚       â”‚   â””â”€â”€ precision_matrix.py    # Î©çŸ©é˜µæ„å»º
â”‚       â”‚
â”‚       â”œâ”€â”€ optimization/              # âš¡ æ€§èƒ½ä¼˜åŒ–æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__. py
â”‚       â”‚   â”œâ”€â”€ scheduler.py           # AdaptiveKernelScheduler
â”‚       â”‚   â”œâ”€â”€ interpolator.py        # SplineInterpolator
â”‚       â”‚   â””â”€â”€ kernel_pool.py         # KernelPoolç¼“å­˜
â”‚       â”‚
â”‚       â”œâ”€â”€ io/                        # ğŸ“ æ•°æ®è¾“å…¥è¾“å‡º
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ segy_reader.py         # SEG-Yæ–‡ä»¶è¯»å–
â”‚       â”‚   â”œâ”€â”€ synthetic. py           # åˆæˆæ•°æ®ç”Ÿæˆ
â”‚       â”‚   â””â”€â”€ exporter.py            # ç»“æœå¯¼å‡º
â”‚       â”‚
â”‚       â”œâ”€â”€ visualization/             # ğŸ“Š å¯è§†åŒ–æ¨¡å—
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ velocity_spectrum.py   # é€Ÿåº¦è°±ç»˜å›¾
â”‚       â”‚   â”œâ”€â”€ comparison.py          # å¯¹æ¯”å›¾
â”‚       â”‚   â””â”€â”€ diagnostics.py         # è¯Šæ–­å›¾ï¼ˆç‰¹å¾åˆ†å¸ƒç­‰ï¼‰
â”‚       â”‚
â”‚       â””â”€â”€ utils/                     # ğŸ› ï¸ å·¥å…·å‡½æ•°
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ validation.py          # æ•°æ®éªŒè¯
â”‚           â”œâ”€â”€ logging_config.py      # æ—¥å¿—é…ç½®
â”‚           â””â”€â”€ metrics.py             # æ€§èƒ½æŒ‡æ ‡è®¡ç®—
â”‚
â”œâ”€â”€ tests/                             # ğŸ§ª æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                    # pytesté…ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ unit/                          # å•å…ƒæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_nmo.py
â”‚   â”‚   â”œâ”€â”€ test_features.py
â”‚   â”‚   â”œâ”€â”€ test_avo_classification.py
â”‚   â”‚   â”œâ”€â”€ test_agent. py
â”‚   â”‚   â”œâ”€â”€ test_factory.py
â”‚   â”‚   â”œâ”€â”€ test_solver.py
â”‚   â”‚   â””â”€â”€ test_interpolator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                   # é›†æˆæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py           # ç«¯åˆ°ç«¯æµç¨‹
â”‚   â”‚   â””â”€â”€ test_optimization.py       # æ€§èƒ½ä¼˜åŒ–éªŒè¯
â”‚   â”‚
â”‚   â””â”€â”€ fixtures/                      # æµ‹è¯•æ•°æ®
â”‚       â”œâ”€â”€ synthetic_cmp. npy
â”‚       â””â”€â”€ expected_outputs.json
â”‚
â”œâ”€â”€ scripts/                           # ğŸš€ å¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ process_cmp.py                 # å¤„ç†å•ä¸ªCMP
â”‚   â”œâ”€â”€ batch_process.py               # æ‰¹é‡å¤„ç†
â”‚   â”œâ”€â”€ benchmark.py                   # æ€§èƒ½æµ‹è¯•
â”‚   â””â”€â”€ generate_synthetic. py          # ç”Ÿæˆæµ‹è¯•æ•°æ®
â”‚
â”œâ”€â”€ notebooks/                         # ğŸ““ Jupyter Notebooksï¼ˆå®éªŒï¼‰
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_analysis.ipynb
â”‚   â”œâ”€â”€ 03_agent_tuning.ipynb
â”‚   â””â”€â”€ 04_results_comparison.ipynb
â”‚
â””â”€â”€ examples/                          # ğŸ“˜ ç¤ºä¾‹ä»£ç 
    â”œâ”€â”€ basic_usage.py                 # åŸºç¡€ä½¿ç”¨
    â”œâ”€â”€ custom_agent.py                # è‡ªå®šä¹‰Agent
    â””â”€â”€ advanced_optimization.py       # é«˜çº§ä¼˜åŒ–
```

---

## æ ¸å¿ƒæ–‡ä»¶è¯¦ç»†è¯´æ˜

### 1. é¡¹ç›®é…ç½®æ–‡ä»¶

#### `pyproject.toml`
```toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "neurosymbolic-avo"
version = "0.1.0"
description = "High-Resolution Velocity Analysis via LLM-Informed Gaussian Processes"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
readme = "README.md"
requires-python = ">=3.9"
license = {text = "MIT"}
keywords = ["seismic", "AVO", "velocity-analysis", "gaussian-processes", "LLM"]

dependencies = [
    "numpy>=1.24.0",
    "scipy>=1.10.0",
    "scikit-learn>=1.3.0",
    "matplotlib>=3.7.0",
    "segyio>=1.9.0",
    "pydantic>=2.0.0",
    "openai>=1.0.0",
    "pyyaml>=6.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.7.0",
    "flake8>=6.1.0",
    "mypy>=1.5.0",
    "jupyter>=1.0.0",
]

[project.scripts]
nsa-process = "neurosymbolic_avo.cli: main"

[tool.black]
line-length = 100
target-version = ['py39']

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v --cov=src/neurosymbolic_avo --cov-report=html"
```

---

#### `requirements.txt`
```txt
# Core dependencies
numpy>=1.24.0
scipy>=1.10.0
scikit-learn>=1.3.0

# Data I/O
segyio>=1.9.0
h5py>=3.9.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# LLM Integration
openai>=1.0.0
langchain>=0.1.0  # Optional:  for advanced LLM orchestration

# Data validation
pydantic>=2.0.0

# Configuration
pyyaml>=6.0
python-dotenv>=1.0.0

# Utilities
tqdm>=4.66.0
colorlog>=6.7.0

# Development (install with:  pip install -e ".[dev]")
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.7.0
flake8>=6.1.0
mypy>=1.5.0
jupyter>=1.0.0
ipywidgets>=8.1.0
```

---

#### `.env.example`
```bash
# OpenAI API Configuration
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4-0125-preview
OPENAI_TEMPERATURE=0.1

# Project Paths
DATA_DIR=./data
RESULTS_DIR=./data/results
LOG_DIR=./data/results/logs

# Performance Settings
N_SPARSE_SAMPLES=10      # Agentè°ƒç”¨çš„å…³é”®æ—¶é—´ç‚¹æ•°é‡
KERNEL_CACHE_ENABLED=true
N_WORKERS=4              # å¹¶è¡Œå¤„ç†çš„è¿›ç¨‹æ•°

# Physics Constraints
DEFAULT_VELOCITY_MIN=2000
DEFAULT_VELOCITY_MAX=4000
DEFAULT_LENGTH_SCALE_MIN=5.0
DEFAULT_LENGTH_SCALE_MAX=50.0

# Logging
LOG_LEVEL=INFO
```

---

#### `.gitignore`
```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*. egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
env/
ENV/

# IDEs
.vscode/
. idea/
*. swp
*.swo
*~

# Jupyter
.ipynb_checkpoints

# Data files (large)
data/raw/*. sgy
data/raw/*.segy
*. npy
*.h5

# Results (too many files)
data/results/*.png
data/results/*.pdf

# Environment variables
.env

# Coverage reports
htmlcov/
.coverage
.coverage.*

# mypy
.mypy_cache/

# pytest
.pytest_cache/
```

---

### 2. åŒ…åˆå§‹åŒ–æ–‡ä»¶

#### `src/neurosymbolic_avo/__init__.py`
```python
"""
NeuroSymbolic AVO Velocity Analysis

A high-resolution velocity analysis system that uses LLM-informed 
Gaussian Processes to eliminate false red zones in velocity spectra. 
"""

__version__ = "0.1.0"
__author__ = "Your Name"

# æ ¸å¿ƒç±»çš„å¿«æ·å¯¼å…¥
from .core.data_structures import CMPGather, SeismicFeatures
from .core.nmo import apply_nmo_correction
from .core. features import FeatureExtractor
from .core.avo_classification import classify_avo, AVOType

from .agent.llm_agent import SeismicAgent
from .agent.blueprint import KernelBlueprint

from .kernel.factory import KernelFactory

from .solver.map_solver import solve_map, solve_map_with_masking

from .io.segy_reader import load_cmp_from_segy
from .io.synthetic import generate_synthetic_cmp

from .visualization.velocity_spectrum import plot_velocity_spectrum

# ä¸»å¤„ç†å‡½æ•°
from .pipeline import process_single_cmp, process_cmp_optimized

__all__ = [
    # Data structures
    "CMPGather",
    "SeismicFeatures",
    "KernelBlueprint",
    "AVOType",
    
    # Core functions
    "apply_nmo_correction",
    "classify_avo",
    
    # Classes
    "FeatureExtractor",
    "SeismicAgent",
    "KernelFactory",
    
    # Solvers
    "solve_map",
    "solve_map_with_masking",
    
    # I/O
    "load_cmp_from_segy",
    "generate_synthetic_cmp",
    
    # Visualization
    "plot_velocity_spectrum",
    
    # Pipeline
    "process_single_cmp",
    "process_cmp_optimized",
]
```

---

### 3. é…ç½®æ–‡ä»¶ç¤ºä¾‹

#### `configs/default.yaml`
```yaml
# Default configuration for NeuroSymbolic AVO

# Data Processing
data: 
  time_window: 
    start: 0.5  # seconds
    end: 2.0
    step: 0.01  # 10ms
  
  velocity_range:
    min: 2000  # m/s
    max: 3500
    n_samples: 50
  
  cmp_geometry:
    n_traces: 30
    offset_max: 1450  # meters

# Agent Configuration
agent:
  model: "gpt-4-0125-preview"
  temperature: 0.1
  max_retries: 3
  fallback_to_rules: true
  
  sparse_sampling:
    enabled: true
    interval: 15  # æ¯15ä¸ªæ—¶é—´çª—å£è°ƒç”¨ä¸€æ¬¡

# Feature Extraction
features:
  zcr_threshold: 0.5
  curvature_threshold: 0.08
  avo_min_r_squared: 0.7
  outlier_z_score: 3.0

# Kernel Configuration
kernel: 
  default_length_scale_bounds: [5.0, 50.0]
  default_variance_bounds: [0.1, 5.0]
  noise_level: 1.0e-6
  
  cache: 
    enabled: true
    quantization_digits: 2

# Optimization
optimization:
  interpolation_method: "cubic_spline"  # or "linear"
  cholesky_max_retries: 3
  cholesky_noise_increment: 10.0

# Visualization
visualization:
  colormap: "seismic_hot"
  dpi: 300
  figsize: [10, 8]
  show_picks: true

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "data/results/logs/processing. log"
```

---

#### `configs/agent_prompts.yaml`
```yaml
system_prompt:  |
  ä½ æ˜¯ä¸€ä½åœ°éœ‡æ•°æ®å¤„ç†ä¸“å®¶ï¼Œä¸“é•¿æ˜¯AVOåˆ†æå’Œé€Ÿåº¦è°±ä¼˜åŒ–ã€‚
  
  ## ä»»åŠ¡
  æ ¹æ®åœ°éœ‡æŒ¯å¹…åºåˆ—çš„ç‰©ç†ç‰¹å¾ï¼Œè®¾è®¡é«˜æ–¯è¿‡ç¨‹çš„æ ¸å‡½æ•°ç»“æ„å’Œè¶…å‚æ•°çº¦æŸã€‚
  
  ## è¾“å…¥ç‰¹å¾è¯´æ˜
  - zero_crossing_rate: [0,1]ï¼Œæ¨ªå‘å˜åŒ–å¿«æ…¢
  - curvature: äºŒé˜¶å¯¼æ•°ï¼ŒRMOå¼¯æ›²ç¨‹åº¦
  - trend_slope: AVOæ¢¯åº¦B
  - avo_type: "I", "II", "III"
  
  ## å†³ç­–è§„åˆ™
  ...  (å®Œæ•´promptå†…å®¹)

few_shot_examples:
  - name: "å¹³æ»‘Iç±»AVO"
    input: 
      zero_crossing_rate: 0.12
      curvature: 0.008
      avo_type: "I"
    output:
      base_kernel_type: "RBF"
      rbf_config:
        length_scale_bounds: [25, 50]
  
  - name: "IIç±»AVO"
    input: 
      zero_crossing_rate:  0.35
      avo_type: "II"
    output:
      base_kernel_type: "RBF+Linear"
      rbf_config:
        length_scale_bounds: [10, 25]
```

---

### 4. ä¸»å¤„ç†ç®¡çº¿

#### `src/neurosymbolic_avo/pipeline. py`
```python
"""
End-to-end processing pipeline. 
"""

import numpy as np
from typing import Optional

from .core.data_structures import CMPGather
from .core.features import FeatureExtractor
from .core.nmo import apply_nmo_correction
from .agent.llm_agent import SeismicAgent
from .kernel.factory import KernelFactory
from .solver.map_solver import solve_map
from .optimization.scheduler import AdaptiveKernelScheduler
from .optimization.interpolator import SplineInterpolator
from .optimization.kernel_pool import KernelPool


def process_single_cmp(
    cmp: CMPGather,
    time_windows: Optional[np.ndarray] = None,
    velocities: Optional[np.ndarray] = None,
    config: Optional[dict] = None
) -> np.ndarray:
    """
    å¤„ç†å•ä¸ªCMPé“é›†ï¼Œç”Ÿæˆé€Ÿåº¦è°±ã€‚
    
    Args:
        cmp: CMPé“é›†
        time_windows: æ—¶é—´çª—å£æ•°ç»„ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤[0.5, 2.0, 0.01]
        velocities: é€Ÿåº¦å€™é€‰æ•°ç»„ï¼ˆç±³/ç§’ï¼‰ï¼Œé»˜è®¤[2000, 3500, 50ç‚¹]
        config: é…ç½®å­—å…¸
    
    Returns:
        semblance: é€Ÿåº¦è°±ï¼Œshape (n_time, n_velocity)
    """
    # ä½¿ç”¨é»˜è®¤é…ç½®
    if time_windows is None:
        time_windows = np.arange(0.5, 2.0, 0.01)
    if velocities is None:
        velocities = np.linspace(2000, 3500, 50)
    
    # ...  (å®Œæ•´å®ç°è§å‰æ–‡)
    pass


def process_cmp_optimized(
    cmp: CMPGather,
    config: Optional[dict] = None
) -> np.ndarray:
    """
    ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆå¸¦æ’å€¼å’Œç¼“å­˜ï¼‰ã€‚
    """
    # ...  (å®Œæ•´å®ç°è§å‰æ–‡)
    pass
```

---

### 5. å‘½ä»¤è¡Œå…¥å£

#### `scripts/process_cmp.py`
```python
#!/usr/bin/env python
"""
å‘½ä»¤è¡Œå·¥å…·ï¼šå¤„ç†å•ä¸ªCMPé“é›†
"""

import argparse
import sys
from pathlib import Path

from neurosymbolic_avo import load_cmp_from_segy, process_cmp_optimized
from neurosymbolic_avo.visualization import plot_velocity_spectrum


def main():
    parser = argparse.ArgumentParser(
        description="NeuroSymbolic AVO Velocity Analysis"
    )
    
    parser.add_argument(
        "input",
        type=str,
        help="Input SEG-Y file path"
    )
    
    parser.add_argument(
        "--cmp",
        type=int,
        required=True,
        help="CMP number to process"
    )
    
    parser.add_argument(
        "--output",
        type=str,
        default="velocity_spectrum.png",
        help="Output figure path"
    )
    
    parser.add_argument(
        "--config",
        type=str,
        default="configs/default.yaml",
        help="Configuration file"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½æ•°æ®
    print(f"Loading CMP {args.cmp} from {args.input}...")
    cmp = load_cmp_from_segy(args.input, args.cmp)
    
    # å¤„ç†
    print("Processing...")
    velocity_spectrum = process_cmp_optimized(cmp)
    
    # å¯è§†åŒ–
    print(f"Saving result to {args.output}...")
    plot_velocity_spectrum(
        velocity_spectrum,
        cmp.time_axis[: velocity_spectrum.shape[0]],
        velocities=np.linspace(2000, 3500, velocity_spectrum.shape[1]),
        save_path=args.output
    )
    
    print("Done!")


if __name__ == "__main__":
    main()
```

---

### 6. READMEæ¨¡æ¿

#### `README.md`
```markdown
# ğŸš€ NeuroSymbolic AVO Velocity Analysis

High-resolution velocity analysis using LLM-informed Gaussian Processes to eliminate false red zones in velocity spectra.

## âœ¨ Features

- ğŸ§  **LLM-Driven Kernel Design**: Agent dynamically synthesizes GP kernels based on data features
- ğŸ“ **Physics-Constrained Optimization**: MAP estimation with physical priors
- âš¡ **Efficient Processing**: Sparse LLM calls + spline interpolation + kernel pooling
- ğŸ¨ **Rich Visualization**: Industry-standard velocity spectrum plots
- ğŸ§ª **Synthetic Data Generation**: Built-in test data generator

## ğŸ“¦ Installation

```bash
# Clone repository
git clone https://github.com/yourusername/neurosymbolic-avo. git
cd neurosymbolic-avo

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install package
pip install -e ".[dev]"

# Set up environment variables
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

## ğŸš€ Quick Start

```python
from neurosymbolic_avo import (
    load_cmp_from_segy,
    process_cmp_optimized,
    plot_velocity_spectrum
)

# Load data
cmp = load_cmp_from_segy("data/raw/stack3d.sgy", cmp_number=1001)

# Process
velocity_spectrum = process_cmp_optimized(cmp)

# Visualize
plot_velocity_spectrum(velocity_spectrum, save_path="result.png")
```

## ğŸ“– Documentation

- [Vibe Coding Document](docs/design/vibe_coding_v2.0.md)
- [Technical Supplement](docs/design/technical_supplement.md)
- [API Reference](docs/api/)

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=src/neurosymbolic_avo --cov-report=html

# Run specific test
pytest tests/unit/test_nmo.py
```

## ğŸ“Š Example Results

![Comparison](docs/images/comparison.png)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

## ğŸ™ Acknowledgments

- Fomel (2009) for AB Semblance algorithm
- Rutherford & Williams (1989) for AVO classification
```

---

## ä½¿ç”¨æµç¨‹

### 1. é¡¹ç›®åˆå§‹åŒ–

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir neurosymbolic-avo
cd neurosymbolic-avo

# åˆå§‹åŒ–git
git init

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"
```

### 2. å¼€å‘å·¥ä½œæµ

```bash
# 1. åˆ›å»ºæ–°åˆ†æ”¯
git checkout -b feature/implement-agent

# 2. ç¼–å†™ä»£ç 
# ç¼–è¾‘ src/neurosymbolic_avo/agent/llm_agent.py

# 3. è¿è¡Œæµ‹è¯•
pytest tests/unit/test_agent.py

# 4. ä»£ç æ ¼å¼åŒ–
black src/

# 5. ç±»å‹æ£€æŸ¥
mypy src/

# 6. æäº¤
git add .
git commit -m "Implement SeismicAgent class"
git push origin feature/implement-agent
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
# ç”Ÿæˆåˆæˆæ•°æ®
python scripts/generate_synthetic. py --output data/synthetic/test_cmp.npy

# å¤„ç†CMP
python scripts/process_cmp.py data/raw/stack3d.sgy --cmp 1001 --output results/cmp1001.png

# æ€§èƒ½æµ‹è¯•
python scripts/benchmark.py
```

---

**é¡¹ç›®ç»“æ„è®¾è®¡å®Œæˆï¼** ğŸ‰

è¿™ä¸ªç»“æ„éµå¾ªäº†Pythoné¡¹ç›®çš„æœ€ä½³å®è·µï¼Œæ¨¡å—åŒ–æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•ã€‚